// Read multiple files and print out the `n` most frequent words in each of them.

let stop_words = ["the", "by", "you", "we", "to", "of", "in", "was", "a", "an", "is",
                  "and", "are", "has", "have", "had", "he", "his", "her", "she", "when",
		  "how", "why", "what", "that", "then", "now", "i", "be", "it", "as",
		  "with", "for", "but", "on", "my", "him", "so", "were", "which", "could",
		  "should", "would", "can", "shall", "will", "me", "at", "not", "they", "all",
		  "been", "from", "very", "much", "no", "yes", "their", "this", "your", "said",
		  "or", "them", "mr", "mrs", "txt", "any", "if", "in", "out", "there", "only",
                  "up", "down", "who", "one", "went", "go", "do", "done", "did", "more", "before",
                  "after", "upon", "into", "other", "these", "ye", "its", "such", "though", "yet",
                  "those", "than", "still", "about", "here", "thou", "thy", "thee", "most", "must",
                  "may"]

let delims = [\space, \newline, \,, \;, \:, \., \_, \-, \{, \}, \(, \), \[, \], \', \", \?, \!]

function word_count(str)
  let (count_table = #{})
   let (add_word_count =
        ^(word)
	 when (string_length(word) > 1 && not(member(word, stop_words)))
           count_table[word] = inc(hashtable_at(count_table, word, 0)))
   { for_each(^(w) add_word_count(string_trim(w)),
                   string_split(string_downcase(str), delims))
     count_table }

function count_words_in_file(file_name)
  let (ct = word_count(call_with_stream(file_reader(file_name),
                       ^(s) read_all_chars(s, file_size(file_name))))
       xs = [])
  { hashtable_for_each(^(k, v) xs = (k:v):xs, ct)
    sort(xs, ^(x, y) tail(x) > tail(y)) }

// Sequentially read and parse each file in the list `file_names`.
function count_words_in_files(file_names)
  let (counts = map(count_words_in_file, file_names),
       count_tables = #{})
  { for_each(^(fn, c) count_tables[fn] = c, file_names, counts)
    count_tables }

function par_counter(file_names)
  act(^(message) | 'start -> count_words_in_files(file_names))

function split(xs)
  letseq (ln = length(xs),
          m = quotient(ln, 2))
    sublist(xs, 0, m):sublist(xs, m, ln)

function merge_tables(t01, t02)
{ hashtable_for_each(^(k, v) t01[k] = v, t02)
  t01 }

// A new parallel version of `count_words_in_files`.
// Split the list `file_names` into two and parse them simultaneously.
function parallel_count_words_in_files(file_names)
  letseq (parts = split(file_names),
          pc = par_counter(head(parts)),
          pcount = pc.start,
          ct01 = count_words_in_files(tail(parts)),
          ct02 = pcount(timeout = 25, default = #{}))
    { pc.quit; merge_tables(ct01, ct02) }

function parallel_count_words_in_files_even_faster(file_names)
  letseq (pcs = map(^(fn) par_counter([fn]), file_names),
          pcounts = map(^(pc) pc.start, pcs),
          to_secs = 15,
          ct = first(pcounts)(timeout = to_secs, default = #{}))
  { for_each(^(pcount) merge_tables(ct, pcount(timeout = to_secs, default = #{})), rest(pcounts))
    for_each(^(pc) pc.quit, pcs)
    ct }

function frequent_words(count_table, n) take(n, count_table)

function par_counter_2(file_names)
  let (counts_table = false)
    act(^(message)
        | 'start -> {!{counts_table = count_words_in_files(file_names)}; true}
        | ['get, fname, n] -> let loop ()
                                if (counts_table) frequent_words(counts_table[fname], n)
                                else { task_sleep(1); loop() })

function count_words_in_files_2(file_names)
  let (counts = map(count_words_in_file, file_names),
       count_tables = #{})
  { for_each(^(fn, c) count_tables[fn] = c, file_names, counts)
    ^(message) | ['get, fname, n] -> frequent_words(count_tables[fname], n)
               | 'quit -> true }

// An updated version of `parallel_count_words_in_files`.
// Instead of returning the complete word_count tables return only
// sub-tables of `n` words.
function parallel_count_words_in_files_2(file_names)
  letseq (parts = split(file_names),
          pc = let (pc = par_counter_2(head(parts)))
                 { pc.start(); pc },
          local_files = tail(parts),
          ct01 = count_words_in_files(local_files))
   ^(message)
   | ['get, fname, n] -> if (member(fname, local_files))
                           frequent_words(ct01[fname], n)
                         else
                           pc(['get, fname, n])()
   | 'quit -> pc.quit


// sample usage:
// files in the corpus were downloaded from Project Gutenberg (https://www.gutenberg.org/)
let corpus = ["./corpus/war&peace.txt", "./corpus/mobydick.txt",
              "./corpus/kjbible.txt", "./corpus/pride&prejudice.txt"]

function frequent_words(count_table, n) take(n, count_table)

// First we compare the original sequential and parallel implementations.
function show_most_frequent_words(corpus, n, count_fn)
  let (start_secs = now_seconds(),
       xs = count_fn(corpus))
  { for (i = 0; i < count(corpus); inc(i))
      let (fname = corpus[i])
        showln(fname, ": ", frequent_words(xs[fname], n))
    showln(now_seconds() - start_secs, " secs") }

show_most_frequent_words(corpus, 20, count_words_in_files)
show_most_frequent_words(corpus, 20, parallel_count_words_in_files)
show_most_frequent_words(corpus, 20, parallel_count_words_in_files_even_faster)

// Next, we compare the sequential and parallel implementations based on
// pure message passing.
function show_most_frequent_words_2(corpus, n, count_fn)
  let (start_secs = now_seconds(),
       xs = count_fn(corpus))
  { for (i = 0; i < count(corpus); inc(i))
      let (fname = corpus[i])
        showln(fname, ": ", xs(['get, fname, n]))
    showln(now_seconds() - start_secs, " secs")
    xs.quit }

show_most_frequent_words_2(corpus, 20, count_words_in_files_2)
show_most_frequent_words_2(corpus, 20, parallel_count_words_in_files_2)